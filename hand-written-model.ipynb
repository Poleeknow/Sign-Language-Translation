{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T16:18:16.354867Z","iopub.status.busy":"2023-11-28T16:18:16.354451Z","iopub.status.idle":"2023-11-28T16:18:20.065018Z","shell.execute_reply":"2023-11-28T16:18:20.063749Z","shell.execute_reply.started":"2023-11-28T16:18:16.354832Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","from torch.nn.utils.rnn import pad_sequence\n","from tqdm import tqdm\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import torch"]},{"cell_type":"markdown","metadata":{},"source":["### Annotaions"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T16:18:20.067489Z","iopub.status.busy":"2023-11-28T16:18:20.066931Z","iopub.status.idle":"2023-11-28T16:18:20.103419Z","shell.execute_reply":"2023-11-28T16:18:20.102215Z","shell.execute_reply.started":"2023-11-28T16:18:20.067454Z"},"trusted":true},"outputs":[],"source":["# Load the annotations\n","annotations_train_path = 'gg/processed_annotations_train.csv'\n","annotations_train = pd.read_csv(annotations_train_path)\n","\n","annotations_val_path = 'gg/processed_annotations_valid.csv'\n","annotations_val = pd.read_csv(annotations_val_path)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T16:18:20.105817Z","iopub.status.busy":"2023-11-28T16:18:20.105411Z","iopub.status.idle":"2023-11-28T16:18:20.127130Z","shell.execute_reply":"2023-11-28T16:18:20.125882Z","shell.execute_reply.started":"2023-11-28T16:18:20.105784Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                       attachment_id        text  \\\n","0  gg/tensors\\train_530cbaa0-c25d-4acd-a6d5-9dcf7...  MakDonalds   \n","1  gg/tensors\\train_aca0a032-9b26-4eee-949e-981c6...  MakDonalds   \n","2  gg/tensors\\train_ed83f161-e83e-4c92-8997-2efda...  MakDonalds   \n","3  gg/tensors\\train_f06bef78-4143-44b1-8d96-741cf...  MakDonalds   \n","4  gg/tensors\\train_e52ee302-7952-4cf6-be52-c80bc...  MakDonalds   \n","\n","                            user_id  height  width  length  train  begin  end  \n","0  db573f94204e56e0cf3fc2ea000e5bdc    1280    720   126.0   True     22   78  \n","1  2d84da20c251acaeb3186642fcb04f2e    1920   1080    68.0   True      6   40  \n","2  0df9d6e419cb18069e696edaa170ba87    1920   1080   114.0   True     19   76  \n","3  95af8e702c909eee7145c6dc1a3d756b    1280    720    85.0   True      1   60  \n","4  0211b488644476dd0fec656ccb9b74fc    1920   1080   121.0   True     23   88  \n"]}],"source":["print(annotations_train.head())"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T16:18:20.131429Z","iopub.status.busy":"2023-11-28T16:18:20.129561Z","iopub.status.idle":"2023-11-28T16:18:20.142513Z","shell.execute_reply":"2023-11-28T16:18:20.140802Z","shell.execute_reply.started":"2023-11-28T16:18:20.131380Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                       attachment_id        text  \\\n","0  gg/tensors\\valid_08ba3f14-0d22-4c96-9e66-d1fed...  MakDonalds   \n","1  gg/tensors\\valid_3d9ffa25-0346-48b4-afc4-16978...  MakDonalds   \n","2  gg/tensors\\valid_3b2832fc-200c-43cc-aa17-3f3aa...  MakDonalds   \n","3  gg/tensors\\valid_758a8d0c-69c7-4605-8884-ac0be...  MakDonalds   \n","4  gg/tensors\\valid_95816840-b7fa-4e4a-b39d-f6e53...  MakDonalds   \n","\n","                            user_id  height  width  length  train  begin  end  \n","0  d2b4042ec6d8505a41b809e64d5adb7c    1920   1080    55.0  False      3   35  \n","1  e4bd328bca8e6f51bd6f4f019692b666    1920   1080    73.0  False      6   45  \n","2  4299b8ccf39ace57287b463fbe4a489b    1920    960   101.0  False     14   66  \n","3  3018b64d2c938f5b6a0826dfdf486f2c    1920   1080   132.0  False     18   94  \n","4  e3e1fd4bbf07a0423ee20d5c9baa49cc    1920   1080    95.0  False     14   71  \n"]}],"source":["print(annotations_val.head())"]},{"cell_type":"markdown","metadata":{},"source":["### Definition of custom dateset class with padding"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T16:18:20.144185Z","iopub.status.busy":"2023-11-28T16:18:20.143804Z","iopub.status.idle":"2023-11-28T16:18:20.156643Z","shell.execute_reply":"2023-11-28T16:18:20.155170Z","shell.execute_reply.started":"2023-11-28T16:18:20.144152Z"},"trusted":true},"outputs":[],"source":["class PaddedSignLanguageDataset(Dataset):\n","    def __init__(self, annotations, transform=None, max_length=None):\n","        \"\"\"\n","        Custom dataset for loading sign language video tensors with padding.\n","        Each video tensor is padded to a uniform length for consistent processing.\n","\n","        :param annotations (DataFrame): DataFrame containing the annotations.\n","        :param transform (callable, optional): Optional transform to be applied on a sample.\n","        :param max_length (int, optional): Maximum length of the video tensors. If not provided, it will be calculated.\n","        \"\"\"\n","        self.annotations = annotations\n","        self.transform = transform\n","        self.max_length = 64\n","        self.tensor_path = \"\"\n","\n","        if self.max_length is None:\n","            # Calculate the maximum length among all tensors\n","            self.max_length = max(len(self.tensor_path + torch.load(row['attachment_id'], map_location=torch.device('cpu'))) for _, row in annotations.iterrows())\n","\n","    def __len__(self):\n","        \"\"\"\n","        Returns the number of samples in the dataset.\n","        \"\"\"\n","        return len(self.annotations)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Returns the sample at the given index.\n","\n","        :param idx (int): Index\n","        :return: Tuple of (video tensor, label)\n","        \"\"\"\n","        tensor_path = self.annotations.iloc[idx]['attachment_id']\n","        label = self.annotations.iloc[idx]['text']\n","        \n","        # Load the tensor\n","        tensor = torch.load(self.tensor_path + tensor_path, map_location=torch.device('cpu'))\n","\n","        # Pad the tensor to the maximum length\n","        padded_tensor = torch.zeros((self.max_length, *tensor[0].shape))\n","        padded_tensor[:len(tensor)] = torch.stack(tensor)\n","                \n","        # Apply transform if any\n","        if self.transform:\n","            padded_tensor = self.transform(padded_tensor)\n","\n","        return padded_tensor, label"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T16:18:20.159151Z","iopub.status.busy":"2023-11-28T16:18:20.158603Z","iopub.status.idle":"2023-11-28T16:18:20.173685Z","shell.execute_reply":"2023-11-28T16:18:20.172436Z","shell.execute_reply.started":"2023-11-28T16:18:20.159108Z"},"trusted":true},"outputs":[],"source":["# Create the padded dataset and dataloader\n","padded_dataset_train = PaddedSignLanguageDataset(annotations_train)\n","padded_dataloader_train = DataLoader(padded_dataset_train, batch_size=16, shuffle=True)\n","\n","padded_dataset_val = PaddedSignLanguageDataset(annotations_val)\n","padded_dataloader_val = DataLoader(padded_dataset_val, batch_size=16, shuffle=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T16:18:23.930455Z","iopub.status.busy":"2023-11-28T16:18:23.930065Z","iopub.status.idle":"2023-11-28T16:18:24.393567Z","shell.execute_reply":"2023-11-28T16:18:24.392418Z","shell.execute_reply.started":"2023-11-28T16:18:23.930426Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Sample tensor shape: torch.Size([16, 64, 3, 64, 64])\n","Sample label: ('Пока', 'Привет!', 'Привет!', 'MakDonalds', 'MakDonalds', 'С днем рождения', 'Добро пожаловать!', 'Привет!', 'Добро пожаловать!', 'Привет!', 'С днем рождения', 'С днем рождения', 'MakDonalds', 'Пока', 'С днем рождения', 'С днем рождения')\n"]}],"source":["# Display a sample from the padded dataset\n","for tensor, label in padded_dataloader_train:\n","    print(\"Sample tensor shape:\", tensor.shape)\n","    print(\"Sample label:\", label)\n","    break  # Display only the first batch"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["### Models definition"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T14:04:21.890949Z","iopub.status.busy":"2023-11-28T14:04:21.890071Z","iopub.status.idle":"2023-11-28T14:04:21.901897Z","shell.execute_reply":"2023-11-28T14:04:21.900882Z","shell.execute_reply.started":"2023-11-28T14:04:21.890910Z"},"trusted":true},"outputs":[],"source":["class TwoStream3DConvNet(nn.Module):\n","    def __init__(self, num_classes):\n","        super(TwoStream3DConvNet, self).__init__()\n","        \"\"\"\n","        A two-stream 3D Convolutional Neural Network for video classification.\n","        This network processes spatial and temporal information separately and then combines them.\n","\n","        :param num_classes (int): Number of classes for classification.\n","        \"\"\"\n","        # Spatial Stream\n","        self.spatial_stream = nn.Sequential(\n","            nn.Conv3d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool3d(kernel_size=2, stride=2),\n","            nn.Conv3d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool3d(kernel_size=2, stride=2)\n","        )\n","        \n","        # Temporal Stream\n","        self.temporal_stream = nn.Sequential(\n","            nn.Conv3d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool3d(kernel_size=2, stride=2),\n","            nn.Conv3d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool3d(kernel_size=2, stride=2)\n","        )\n","        \n","        # Fully Connected Layers\n","        self.fc1 = nn.Linear(262144, 512)\n","        self.fc2 = nn.Linear(512, num_classes)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass of the network.\n","\n","        :param x (Tensor): Input tensor of shape (batch_size, 3, max_length, 112, 112)\n","        :return: Output tensor of shape (batch_size, num_classes)\n","        \"\"\"\n","        spatial_out = self.spatial_stream(x)\n","        temporal_out = self.temporal_stream(x)\n","        \n","        # Concatenate the outputs of the two streams\n","        combined = torch.cat((spatial_out, temporal_out), dim=1)\n","        \n","        combined = torch.flatten(combined, 1)\n","        combined = self.relu(self.fc1(combined))\n","        combined = self.fc2(combined)\n","        return combined"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T14:04:23.009791Z","iopub.status.busy":"2023-11-28T14:04:23.009295Z","iopub.status.idle":"2023-11-28T14:04:25.248562Z","shell.execute_reply":"2023-11-28T14:04:25.247728Z","shell.execute_reply.started":"2023-11-28T14:04:23.009752Z"},"trusted":true},"outputs":[],"source":["num_classes = len(set(annotations_train['text']))\n","\n","models = {\n","#     'simple_3d_conv_net': Simple3DConvNet(num_classes),\n","    'two_stream_3d_conv_net': TwoStream3DConvNet(num_classes)\n","#     'resnet3d': ResNet3D(num_classes)\n","}"]},{"cell_type":"markdown","metadata":{},"source":["### Labels Mapping"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T14:04:28.153842Z","iopub.status.busy":"2023-11-28T14:04:28.152989Z","iopub.status.idle":"2023-11-28T14:04:31.499877Z","shell.execute_reply":"2023-11-28T14:04:31.498876Z","shell.execute_reply.started":"2023-11-28T14:04:28.153809Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Label Mapping: {'MakDonalds': 0, 'Добро пожаловать!': 1, 'Пока': 2, 'Привет!': 3, 'С днем рождения': 4}\n"]}],"source":["# Initialize an empty set to collect unique labels\n","unique_labels_train = set()\n","\n","# Iterate over your dataset to collect unique labels\n","for _, label_data in padded_dataloader_train:\n","    unique_labels_train.update(label_data)\n","\n","# Sort the labels for consistency\n","sorted_labels = sorted(unique_labels_train)\n","\n","# Create the label mapping\n","train_label_mapping = {label: idx for idx, label in enumerate(sorted_labels)}\n","\n","# Print the label mapping\n","print(\"Label Mapping:\", train_label_mapping)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T14:04:31.501821Z","iopub.status.busy":"2023-11-28T14:04:31.501384Z","iopub.status.idle":"2023-11-28T14:04:32.601181Z","shell.execute_reply":"2023-11-28T14:04:32.600149Z","shell.execute_reply.started":"2023-11-28T14:04:31.501792Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Label Mapping: {'MakDonalds': 0, 'Добро пожаловать!': 1, 'Пока': 2, 'Привет!': 3, 'С днем рождения': 4}\n"]}],"source":["# Initialize an empty set to collect unique labels\n","unique_labels_test = set()\n","\n","# Iterate over your dataset to collect unique labels\n","for _, label_data in padded_dataloader_val:\n","    unique_labels_test.update(label_data)\n","\n","# Sort the labels for consistency\n","sorted_labels = sorted(unique_labels_test)\n","\n","# Create the label mapping\n","val_label_mapping = {label: idx for idx, label in enumerate(sorted_labels)}\n","\n","# Print the label mapping\n","print(\"Label Mapping:\", val_label_mapping)"]},{"cell_type":"markdown","metadata":{},"source":["### Train and Validation loops"]},{"cell_type":"markdown","metadata":{},"source":["### Plotting"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T16:18:02.664689Z","iopub.status.busy":"2023-11-28T16:18:02.663869Z","iopub.status.idle":"2023-11-28T16:18:03.029352Z","shell.execute_reply":"2023-11-28T16:18:03.027728Z","shell.execute_reply.started":"2023-11-28T16:18:02.664647Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training two_stream_3d_conv_net\n"]},{"name":"stderr","output_type":"stream","text":["d:\\miniconda3\\envs\\torch-cuda-2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","Epoch 1/25 - Training: 100%|██████████| 5/5 [00:25<00:00,  5.00s/it, accuracy=0.253, loss=197] \n","Epoch 1/25 - Validation: 100%|██████████| 2/2 [00:01<00:00,  1.05it/s, accuracy=0.28, loss=18.7]\n","Epoch 2/25 - Training: 100%|██████████| 5/5 [00:25<00:00,  5.01s/it, accuracy=0.36, loss=12.3] \n","Epoch 2/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.02s/it, accuracy=0.32, loss=0.658]\n"]},{"name":"stdout","output_type":"stream","text":["new best\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/25 - Training: 100%|██████████| 5/5 [00:27<00:00,  5.59s/it, accuracy=0.387, loss=0.833]\n","Epoch 3/25 - Validation: 100%|██████████| 2/2 [00:01<00:00,  1.05it/s, accuracy=0.2, loss=0.363]  \n","Epoch 4/25 - Training: 100%|██████████| 5/5 [00:27<00:00,  5.49s/it, accuracy=0.52, loss=0.514] \n","Epoch 4/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it, accuracy=0.24, loss=0.404]\n","Epoch 5/25 - Training: 100%|██████████| 5/5 [00:28<00:00,  5.68s/it, accuracy=0.627, loss=0.471] \n","Epoch 5/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it, accuracy=0.24, loss=0.413] \n","Epoch 6/25 - Training: 100%|██████████| 5/5 [00:29<00:00,  5.96s/it, accuracy=0.653, loss=0.374]\n","Epoch 6/25 - Validation: 100%|██████████| 2/2 [00:01<00:00,  1.03it/s, accuracy=0.2, loss=0.378]  \n","Epoch 7/25 - Training: 100%|██████████| 5/5 [00:26<00:00,  5.30s/it, accuracy=0.84, loss=0.242]  \n","Epoch 7/25 - Validation: 100%|██████████| 2/2 [00:01<00:00,  1.02it/s, accuracy=0.2, loss=0.459]  \n","Epoch 8/25 - Training: 100%|██████████| 5/5 [00:27<00:00,  5.46s/it, accuracy=0.84, loss=0.189]  \n","Epoch 8/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it, accuracy=0.16, loss=0.457] \n","Epoch 9/25 - Training: 100%|██████████| 5/5 [00:27<00:00,  5.56s/it, accuracy=0.973, loss=0.099] \n","Epoch 9/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.00s/it, accuracy=0.28, loss=0.437]\n","Epoch 10/25 - Training: 100%|██████████| 5/5 [00:28<00:00,  5.71s/it, accuracy=1, loss=0.0395] \n","Epoch 10/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.04s/it, accuracy=0.36, loss=0.587]\n"]},{"name":"stdout","output_type":"stream","text":["new best\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 11/25 - Training: 100%|██████████| 5/5 [00:28<00:00,  5.79s/it, accuracy=1, loss=0.0141] \n","Epoch 11/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it, accuracy=0.4, loss=0.586]  \n"]},{"name":"stdout","output_type":"stream","text":["new best\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 12/25 - Training: 100%|██████████| 5/5 [00:30<00:00,  6.08s/it, accuracy=1, loss=0.00678]\n","Epoch 12/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it, accuracy=0.36, loss=0.702] \n","Epoch 13/25 - Training: 100%|██████████| 5/5 [00:30<00:00,  6.04s/it, accuracy=1, loss=0.00129] \n","Epoch 13/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.06s/it, accuracy=0.32, loss=0.913] \n","Epoch 14/25 - Training: 100%|██████████| 5/5 [00:28<00:00,  5.63s/it, accuracy=1, loss=0.000437]\n","Epoch 14/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it, accuracy=0.32, loss=0.995] \n","Epoch 15/25 - Training: 100%|██████████| 5/5 [00:31<00:00,  6.40s/it, accuracy=1, loss=9.49e-5]\n","Epoch 15/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it, accuracy=0.32, loss=1.1]   \n","Epoch 16/25 - Training: 100%|██████████| 5/5 [00:30<00:00,  6.06s/it, accuracy=1, loss=4.96e-5]\n","Epoch 16/25 - Validation: 100%|██████████| 2/2 [00:01<00:00,  1.08it/s, accuracy=0.32, loss=1.12]  \n","Epoch 17/25 - Training: 100%|██████████| 5/5 [00:27<00:00,  5.55s/it, accuracy=1, loss=2.96e-5]\n","Epoch 17/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it, accuracy=0.32, loss=1.15]  \n","Epoch 18/25 - Training: 100%|██████████| 5/5 [00:26<00:00,  5.38s/it, accuracy=1, loss=1.36e-5]\n","Epoch 18/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it, accuracy=0.32, loss=1.13] \n","Epoch 19/25 - Training: 100%|██████████| 5/5 [00:26<00:00,  5.36s/it, accuracy=1, loss=7.56e-6]\n","Epoch 19/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.03s/it, accuracy=0.32, loss=1.19]  \n","Epoch 20/25 - Training: 100%|██████████| 5/5 [00:28<00:00,  5.66s/it, accuracy=1, loss=5.95e-6]\n","Epoch 20/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.02s/it, accuracy=0.32, loss=1.22]  \n","Epoch 21/25 - Training: 100%|██████████| 5/5 [00:29<00:00,  5.95s/it, accuracy=1, loss=4.62e-6]\n","Epoch 21/25 - Validation: 100%|██████████| 2/2 [00:02<00:00,  1.03s/it, accuracy=0.32, loss=1.34]  \n","Epoch 22/25 - Training: 100%|██████████| 5/5 [00:24<00:00,  4.95s/it, accuracy=1, loss=3.81e-6]\n","Epoch 22/25 - Validation: 100%|██████████| 2/2 [00:01<00:00,  1.03it/s, accuracy=0.32, loss=1.37]\n","Epoch 23/25 - Training: 100%|██████████| 5/5 [00:24<00:00,  4.93s/it, accuracy=1, loss=3.25e-6]\n","Epoch 23/25 - Validation: 100%|██████████| 2/2 [00:01<00:00,  1.09it/s, accuracy=0.32, loss=1.27] \n","Epoch 24/25 - Training: 100%|██████████| 5/5 [00:24<00:00,  4.97s/it, accuracy=1, loss=3.12e-6]\n","Epoch 24/25 - Validation: 100%|██████████| 2/2 [00:01<00:00,  1.01it/s, accuracy=0.32, loss=1.21] \n","Epoch 25/25 - Training: 100%|██████████| 5/5 [00:26<00:00,  5.22s/it, accuracy=1, loss=2.76e-6]\n","Epoch 25/25 - Validation: 100%|██████████| 2/2 [00:01<00:00,  1.01it/s, accuracy=0.32, loss=1.21] "]},{"name":"stdout","output_type":"stream","text":["Finished Training\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","num_epochs = 25\n","results = {}\n","\n","best_score = 0.28\n","# Train the models\n","# Training and Validation\n","for model_name, model in models.items():\n","    print(f\"Training {model_name}\")\n","\n","    # Loss function and optimizer\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","    # List to store epoch-wise validation accuracies for the current model\n","    epoch_val_accuracies = []\n","\n","    for epoch in range(num_epochs):\n","        running_loss = 0.0\n","        correct_predictions = 0\n","        total_predictions = 0\n","\n","        # Training Phase\n","        model.train()\n","        loop = tqdm(enumerate(padded_dataloader_train, 0), total=len(padded_dataloader_train), desc=f\"Epoch {epoch+1}/{num_epochs} - Training\")\n","        for i, data in loop:\n","            inputs, label_data = data\n","            target_labels = torch.tensor([train_label_mapping[label] for label in label_data], dtype=torch.long)\n","#             print(target_labels)\n","            inputs = inputs.permute(0, 2, 1, 3, 4)\n","            labels = torch.zeros((len(target_labels), 5))\n","            for i, label in enumerate(target_labels):\n","                labels[i, label] = 1\n","            \n","#             print(target_labels[0], labels[0])\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            \n","#             print(outputs)\n","            loss = criterion(outputs, labels)\n","#             print(loss)\n","            loss.backward()\n","\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total_predictions += labels.size(0)\n","#             print(predicted)\n","#             print(target_labels)\n","            correct_predictions += (predicted == target_labels).sum().item()\n","\n","            # Update progress bar\n","            loop.set_description(f\"Epoch {epoch+1}/{num_epochs} - Training\")\n","            loop.set_postfix(loss = running_loss / (i+1), accuracy = correct_predictions / total_predictions)\n","\n","        # Validation Phase\n","        model.eval()\n","        val_running_loss = 0.0\n","        val_correct_predictions = 0\n","        val_total_predictions = 0\n","        loop_val = tqdm(enumerate(padded_dataloader_val, 0), total=len(padded_dataloader_val), desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\")\n","        for i, data in loop_val:\n","            inputs, label_data = data\n","\n","            if len(inputs) == 0 or len(label_data) == 0:\n","                continue\n","\n","#             labels = torch.tensor([val_label_mapping.get(label) for label in label_data], dtype=torch.long)\n","#             inputs = inputs.permute(0, 2, 1, 3, 4)\n","            target_labels = torch.tensor([train_label_mapping[label] for label in label_data], dtype=torch.long)\n","#             print(target_labels)\n","            inputs = inputs.permute(0, 2, 1, 3, 4)\n","            labels = torch.zeros((len(target_labels), 5))\n","            for i, label in enumerate(target_labels):\n","                labels[i, label] = 1\n","            \n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_running_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            val_total_predictions += labels.size(0)\n","#             print((predicted == target_labels).sum().item())\n","            val_correct_predictions += (predicted == target_labels).sum().item()\n","\n","            # Update progress bar\n","            loop_val.set_description(f\"Epoch {epoch+1}/{num_epochs} - Validation\")\n","            loop_val.set_postfix(loss = val_running_loss / (i+1), accuracy = val_correct_predictions / val_total_predictions)\n","\n","        val_accuracy = val_correct_predictions / val_total_predictions\n","        epoch_val_accuracies.append(val_accuracy)\n","        \n","        if val_correct_predictions / val_total_predictions > best_score:\n","            print(\"new best\")\n","            best_score = val_correct_predictions / val_total_predictions\n","            torch.save(model.state_dict(), model_name + \".pt\")\n","\n","    # Store the epoch-wise validation accuracies for this model\n","    results[model_name] = epoch_val_accuracies\n","    \n","print('Finished Training')\n"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2023-11-28T15:25:05.338263Z","iopub.status.busy":"2023-11-28T15:25:05.337867Z","iopub.status.idle":"2023-11-28T15:25:05.355058Z","shell.execute_reply":"2023-11-28T15:25:05.354262Z","shell.execute_reply.started":"2023-11-28T15:25:05.338232Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>attachment_id</th>\n","      <th>text</th>\n","      <th>user_id</th>\n","      <th>height</th>\n","      <th>width</th>\n","      <th>length</th>\n","      <th>train</th>\n","      <th>begin</th>\n","      <th>end</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>gg/tensors\\valid_758a8d0c-69c7-4605-8884-ac0be...</td>\n","      <td>MakDonalds</td>\n","      <td>3018b64d2c938f5b6a0826dfdf486f2c</td>\n","      <td>1920</td>\n","      <td>1080</td>\n","      <td>132.0</td>\n","      <td>False</td>\n","      <td>18</td>\n","      <td>94</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                       attachment_id        text  \\\n","3  gg/tensors\\valid_758a8d0c-69c7-4605-8884-ac0be...  MakDonalds   \n","\n","                            user_id  height  width  length  train  begin  end  \n","3  3018b64d2c938f5b6a0826dfdf486f2c    1920   1080   132.0  False     18   94  "]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["hello_sign = annotations_val.query(\"text == 'MakDonalds'\").sample(1)\n","hello_sign"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["hello_sign_dataset = PaddedSignLanguageDataset(hello_sign)\n","hello_sign_dataloader = DataLoader(hello_sign_dataset, shuffle=False)"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["model = TwoStream3DConvNet(num_classes)\n","\n","model_path = \"checkpoints/two_stream_3d_conv_net_val04.pt\"\n","model.load_state_dict(torch.load(model_path)) "]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"data":{"text/plain":["TwoStream3DConvNet(\n","  (spatial_stream): Sequential(\n","    (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (1): ReLU()\n","    (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (4): ReLU()\n","    (5): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (temporal_stream): Sequential(\n","    (0): Conv3d(3, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (1): ReLU()\n","    (2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n","    (4): ReLU()\n","    (5): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (fc1): Linear(in_features=262144, out_features=512, bias=True)\n","  (fc2): Linear(in_features=512, out_features=5, bias=True)\n","  (relu): ReLU()\n",")"]},"execution_count":56,"metadata":{},"output_type":"execute_result"}],"source":["model"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["model.eval()\n","window_size = 16\n","threshold = 0.5\n","frame_interval = 1\n","mean = [123.675, 116.28, 103.53]\n","std = [58.395, 57.12, 57.375]"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MakDonalds\n"]}],"source":["print(hello_sign_dataset[0][1])"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n"]}],"source":["print(len(hello_sign_dataloader))"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([64, 3, 64, 64])\n","torch.Size([1, 3, 64, 64, 64])\n","Predicted class: 0, Target class: MakDonalds\n"]}],"source":["inputs, label_data = hello_sign_dataset[0]\n","print(inputs.shape)\n","inputs = inputs.reshape((1, 3, 64, 64, 64))\n","print(inputs.shape)\n","out = model(inputs)\n","pred_class = torch.argmax(out)\n","print(f\"Predicted class: {pred_class}, Target class: {label_data}\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4069680,"sourceId":7067475,"sourceType":"datasetVersion"}],"dockerImageVersionId":30587,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
