{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attachment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>length</th>\n",
       "      <th>train</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44e8d2a0-7e01-450b-90b0-beb7400d2c1e</td>\n",
       "      <td>Ё</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>156.0</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df5b08f0-41d1-4572-889c-8b893e71069b</td>\n",
       "      <td>А</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>150.0</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17f53df4-c467-4aff-9f48-20687b63d49a</td>\n",
       "      <td>Р</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>133.0</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e3add916-c708-4339-ad98-7e2740be29e9</td>\n",
       "      <td>Е</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>144.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bd7272ed-1850-48f1-a2a8-c8fed523dc37</td>\n",
       "      <td>Ч</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>96.0</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          attachment_id text  \\\n",
       "0  44e8d2a0-7e01-450b-90b0-beb7400d2c1e    Ё   \n",
       "1  df5b08f0-41d1-4572-889c-8b893e71069b    А   \n",
       "2  17f53df4-c467-4aff-9f48-20687b63d49a    Р   \n",
       "3  e3add916-c708-4339-ad98-7e2740be29e9    Е   \n",
       "4  bd7272ed-1850-48f1-a2a8-c8fed523dc37    Ч   \n",
       "\n",
       "                            user_id  height  width  length  train  begin  end  \n",
       "0  185bd3a81d9d618518d10abebf0d17a8    1920   1080   156.0   True     36  112  \n",
       "1  185bd3a81d9d618518d10abebf0d17a8    1920   1080   150.0   True     36   76  \n",
       "2  185bd3a81d9d618518d10abebf0d17a8    1920   1080   133.0   True     40   97  \n",
       "3  185bd3a81d9d618518d10abebf0d17a8    1920   1080   144.0   True     43  107  \n",
       "4  185bd3a81d9d618518d10abebf0d17a8    1920   1080    96.0   True     20   70  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot = pd.read_csv(\"data/annotations.csv\", sep='\\t')\n",
    "annot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Привет!\",\"Добро пожаловать!\",\"С днем рождения\",\"Пока\", \"MakDonalds\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train150 = annot.query(\"text in @labels and train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val50 = annot.query(\"text in @labels and not train\")\n",
    "val50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_frame(frame):\n",
    "    \"\"\"\n",
    "    Crops the frame to a square shape\n",
    "    :param frame: frame to crop\n",
    "    :return: cropped frame\n",
    "    \"\"\"\n",
    "    height, width = frame.shape[:2]\n",
    "    th_dim = frame.shape[2]\n",
    "    max_dim = max(height, width)\n",
    "    dif = abs(height-width)\n",
    "\n",
    "    first_side = dif // 2\n",
    "    second_side = dif - first_side\n",
    "    \n",
    "    \n",
    "    if width == max_dim:\n",
    "        f_array = np.zeros(shape=(first_side, max_dim, th_dim))\n",
    "        s_array = np.zeros(shape=(second_side, max_dim, th_dim))\n",
    "        frame = np.concatenate((f_array, np.array(frame), s_array), axis=0)\n",
    "    else:\n",
    "        f_array = np.zeros(shape=(max_dim, first_side, th_dim))\n",
    "        s_array = np.zeros(shape=(max_dim, second_side, th_dim))\n",
    "        frame = np.concatenate((f_array, np.array(frame), s_array), axis=1)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path, img_size, num_frames=132):\n",
    "    \"\"\"\n",
    "    Loads the video from the path and returns a tensor of frames\n",
    "    :param path: path to the video\n",
    "    :param img_size: size of the image\n",
    "    :param num_frames: number of frames to sample\n",
    "    :return: tensor of frames\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    i = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i % 4 == 0:\n",
    "            frame = crop_frame(frame)\n",
    "            frame = cv2.resize(frame, (img_size, img_size))\n",
    "            frame = frame[:, :, [2, 1, 0]]  # BGR to RGB\n",
    "            frame_tensor = torch.Tensor(frame).permute(2, 0, 1).to(device)\n",
    "            frames.append(frame_tensor)\n",
    "        i += 1\n",
    "        \n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "tensor_dir = \"tensors\"\n",
    "Path(tensor_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_tensors(annot_subset, subset_name, subdir = 'train'):\n",
    "    \"\"\"\n",
    "    Processes and saves tensors to disk\n",
    "    :param annot_subset: DataFrame with annotations\n",
    "    :param subset_name: name of the subset\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for ind, row in annot_subset.iterrows():\n",
    "        path = row['attachment_id']\n",
    "        full_path = \"/kaggle/input/slovo/slovo/\" + str(subdir) + \"/\" + str(path) + \".mp4\"\n",
    "\n",
    "        # Load and process video\n",
    "        frames = load_video(full_path, 244, 244)\n",
    "    \n",
    "        # Save tensor to disk and store path in DataFrame\n",
    "        tensor_dir = \"tensors\"\n",
    "        tensor_path = os.path.join(tensor_dir, f\"{subset_name}_{path}.pt\")\n",
    "        torch.save(frames, tensor_path)\n",
    "        annot_subset.loc[ind, 'attachment_id'] = str(tensor_path)\n",
    "        \n",
    "        i += 1\n",
    "        if i % 10 == 0:\n",
    "            print(f\"We are done on the image number {i}\")\n",
    "    \n",
    "    # Save DataFrame to CSV\n",
    "    annot_subset.to_csv(f\"processed_annotations_{subset_name}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_and_save_tensors(train150, \"train\", subdir = 'train')\n",
    "process_and_save_tensors(val50, \"valid\", subdir = 'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
