{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: NVIDIA GeForce GTX 1650 Ti\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of transferring a tensor to GPU\n",
    "tensor_on_gpu = torch.Tensor([1.0, 2.0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attachment_id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>length</th>\n",
       "      <th>train</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44e8d2a0-7e01-450b-90b0-beb7400d2c1e</td>\n",
       "      <td>Ё</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>156.0</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df5b08f0-41d1-4572-889c-8b893e71069b</td>\n",
       "      <td>А</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>150.0</td>\n",
       "      <td>True</td>\n",
       "      <td>36</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17f53df4-c467-4aff-9f48-20687b63d49a</td>\n",
       "      <td>Р</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>133.0</td>\n",
       "      <td>True</td>\n",
       "      <td>40</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e3add916-c708-4339-ad98-7e2740be29e9</td>\n",
       "      <td>Е</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>144.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bd7272ed-1850-48f1-a2a8-c8fed523dc37</td>\n",
       "      <td>Ч</td>\n",
       "      <td>185bd3a81d9d618518d10abebf0d17a8</td>\n",
       "      <td>1920</td>\n",
       "      <td>1080</td>\n",
       "      <td>96.0</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          attachment_id text  \\\n",
       "0  44e8d2a0-7e01-450b-90b0-beb7400d2c1e    Ё   \n",
       "1  df5b08f0-41d1-4572-889c-8b893e71069b    А   \n",
       "2  17f53df4-c467-4aff-9f48-20687b63d49a    Р   \n",
       "3  e3add916-c708-4339-ad98-7e2740be29e9    Е   \n",
       "4  bd7272ed-1850-48f1-a2a8-c8fed523dc37    Ч   \n",
       "\n",
       "                            user_id  height  width  length  train  begin  end  \n",
       "0  185bd3a81d9d618518d10abebf0d17a8    1920   1080   156.0   True     36  112  \n",
       "1  185bd3a81d9d618518d10abebf0d17a8    1920   1080   150.0   True     36   76  \n",
       "2  185bd3a81d9d618518d10abebf0d17a8    1920   1080   133.0   True     40   97  \n",
       "3  185bd3a81d9d618518d10abebf0d17a8    1920   1080   144.0   True     43  107  \n",
       "4  185bd3a81d9d618518d10abebf0d17a8    1920   1080    96.0   True     20   70  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot = pd.read_csv(\"data/annotations.csv\", sep='\\t')\n",
    "annot.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a subset of 100 items for training\n",
    "train_annot = annot[annot['train']].sample(100).reset_index(drop=True)\n",
    "\n",
    "# Use a subset of 100 items for validation\n",
    "valid_annot = annot[~annot['train']].sample(100).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   attachment_id  100 non-null    object \n",
      " 1   text           100 non-null    object \n",
      " 2   user_id        100 non-null    object \n",
      " 3   height         100 non-null    int64  \n",
      " 4   width          100 non-null    int64  \n",
      " 5   length         100 non-null    float64\n",
      " 6   train          100 non-null    bool   \n",
      " 7   begin          100 non-null    int64  \n",
      " 8   end            100 non-null    int64  \n",
      "dtypes: bool(1), float64(1), int64(4), object(3)\n",
      "memory usage: 6.5+ KB\n"
     ]
    }
   ],
   "source": [
    "train_annot.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   attachment_id  100 non-null    object \n",
      " 1   text           100 non-null    object \n",
      " 2   user_id        100 non-null    object \n",
      " 3   height         100 non-null    int64  \n",
      " 4   width          100 non-null    int64  \n",
      " 5   length         100 non-null    float64\n",
      " 6   train          100 non-null    bool   \n",
      " 7   begin          100 non-null    int64  \n",
      " 8   end            100 non-null    int64  \n",
      "dtypes: bool(1), float64(1), int64(4), object(3)\n",
      "memory usage: 6.5+ KB\n"
     ]
    }
   ],
   "source": [
    "valid_annot.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_frame(frame):\n",
    "    \"\"\"\n",
    "    Crops the frame to a square shape\n",
    "    :param frame: frame to crop\n",
    "    :return: cropped frame\n",
    "    \"\"\"\n",
    "    height, width = frame.shape[:2]\n",
    "    th_dim = frame.shape[2]\n",
    "    max_dim = max(height, width)\n",
    "    dif = abs(height-width)\n",
    "\n",
    "    first_side = dif // 2\n",
    "    second_side = dif - first_side\n",
    "    \n",
    "    \n",
    "    if width == max_dim:\n",
    "        f_array = np.zeros(shape=(first_side, max_dim, th_dim))\n",
    "        s_array = np.zeros(shape=(second_side, max_dim, th_dim))\n",
    "        frame = np.concatenate((f_array, np.array(frame), s_array), axis=0)\n",
    "    else:\n",
    "        f_array = np.zeros(shape=(max_dim, first_side, th_dim))\n",
    "        s_array = np.zeros(shape=(max_dim, second_side, th_dim))\n",
    "        frame = np.concatenate((f_array, np.array(frame), s_array), axis=1)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path, img_size, i):\n",
    "    \"\"\"\n",
    "    Loads the video from the path and returns a list of frames\n",
    "    :param path: path to the video\n",
    "    :param img_size: size of the image\n",
    "    :param i: index of the video\n",
    "    :return: list of frames\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        else:\n",
    "            frame = crop_frame(frame)\n",
    "            frame = cv2.resize(frame, (img_size, img_size))\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frame_tensor = torch.Tensor(frame).permute(2, 0, 1).to(device)\n",
    "            frames.append(frame_tensor)\n",
    "            \n",
    "    if i < 100 and i % 10 == 0 or i % 100 == 0:\n",
    "        print(f\"We are done on the image number {i}\")\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, path in enumerate(annot['attachment_id']):\n",
    "#     full_path = \"data/slovo/train/\" + str(path) + \".mp4\"\n",
    "#     annot.at[i, 'attachment_id'] = load_video(full_path, 100, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_dir = \"data/tensors/\"\n",
    "os.makedirs(tensor_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_tensors(annot_subset, subset_name):\n",
    "    \"\"\"\n",
    "    Processes and saves tensors to disk\n",
    "    :param annot_subset: DataFrame with annotations\n",
    "    :param subset_name: name of the subset\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    for i, path in enumerate(annot_subset['attachment_id']):\n",
    "        full_path = \"data/slovo/train/\" + str(path) + \".mp4\"\n",
    "\n",
    "        # Load and process video\n",
    "        frames = load_video(full_path, 100, i)\n",
    "    \n",
    "        # Save tensor to disk and store path in DataFrame\n",
    "        tensor_path = os.path.join(tensor_dir, f\"{subset_name}_{path}.pt\")\n",
    "        torch.save(frames, tensor_path)\n",
    "        annot_subset.at[i, 'attachment_id'] = tensor_path\n",
    "    \n",
    "    # Save DataFrame to CSV\n",
    "    annot_subset.to_csv(f\"data/processed_annotations_{subset_name}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are done on the image number 0\n",
      "We are done on the image number 10\n",
      "We are done on the image number 20\n",
      "We are done on the image number 30\n",
      "We are done on the image number 40\n",
      "We are done on the image number 50\n",
      "We are done on the image number 60\n",
      "We are done on the image number 70\n",
      "We are done on the image number 80\n",
      "We are done on the image number 90\n"
     ]
    }
   ],
   "source": [
    "# Process and save tensors for training and validation subsets\n",
    "process_and_save_tensors(train_annot, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are done on the image number 0\n",
      "We are done on the image number 10\n",
      "We are done on the image number 20\n",
      "We are done on the image number 30\n",
      "We are done on the image number 40\n",
      "We are done on the image number 50\n",
      "We are done on the image number 60\n",
      "We are done on the image number 70\n",
      "We are done on the image number 80\n",
      "We are done on the image number 90\n"
     ]
    }
   ],
   "source": [
    "process_and_save_tensors(valid_annot, \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "annot = pd.read_csv(\"data/processed_annotations_train.csv\")\n",
    "\n",
    "# Load the first tensor\n",
    "first_tensor_path = annot['attachment_id'].iloc[0]\n",
    "first_tensor = torch.load(first_tensor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first frame is not NaN or zeros.\n"
     ]
    }
   ],
   "source": [
    "if torch.isnan(first_tensor[0]).any():\n",
    "    print(\"The first frame contains NaN values!\")\n",
    "elif torch.equal(first_tensor[0], torch.zeros_like(first_tensor[0])):\n",
    "    print(\"The first frame is all zeros!\")\n",
    "else:\n",
    "    print(\"The first frame is not NaN or zeros.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
