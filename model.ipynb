{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Transforming to tensors"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import numpy as np\n","import pandas as pd\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","from PIL import Image"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# train_tensors = list(annot_train150['attachment_id'])\n","# val_tensors = list(annot_val50['attachment_id'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class PaddedSignLanguageDataset(Dataset):\n","    def __init__(self, annotations, transform=None, max_length=None):\n","        \"\"\"\n","        Corrected custom dataset for loading sign language video tensors with padding.\n","\n","        Args:\n","        annotations (DataFrame): DataFrame containing the annotations.\n","        transform (callable, optional): Optional transform to be applied on a sample.\n","        max_length (int, optional): Maximum length of the video tensors. If not provided, it will be calculated.\n","        \"\"\"\n","        self.annotations = annotations\n","        self.transform = transform\n","        self.max_length = 132\n","\n","        if self.max_length is None:\n","            # Calculate the maximum length among all tensors\n","            self.max_length = max(len(torch.load(row['attachment_id'], map_location=torch.device('cpu'))) for _, row in annotations.iterrows())\n","\n","    def __len__(self):\n","        return len(self.annotations)\n","\n","    def __getitem__(self, idx):\n","        tensor_path = self.annotations.iloc[idx]['attachment_id']\n","        label = self.annotations.iloc[idx]['text']\n","        \n","        # Load the tensor\n","        tensor = torch.load(tensor_path, map_location=torch.device('cpu'))\n","\n","        # Check if the tensor is empty or None\n","        if tensor is None or len(tensor) == 0:\n","            print(f\"Empty tensor found at index {idx}.\")\n","            return None, label\n","\n","\n","        # Pad the tensor to the maximum length\n","        padded_tensor = torch.zeros((self.max_length, *tensor[0].shape))\n","        padded_tensor[:len(tensor)] = torch.stack(tensor)\n","                \n","        # Apply transform if any\n","        if self.transform:\n","            padded_tensor = self.transform(padded_tensor)\n","\n","        return padded_tensor, label"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_dataset = PaddedSignLanguageDataset(annot_train150)\n","val_dataset = PaddedSignLanguageDataset(annot_val50)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["num_classes = 10\n","train_data_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n","val_data_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_path = \"/kaggle/input/mvit16-4/mvit16-4.pt\"\n","model = torch.jit.load(model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.eval()\n","window_size = 16 # from model name\n","threshold = 0.5\n","frame_interval = 1\n","mean = [123.675, 116.28, 103.53]\n","std = [58.395, 57.12, 57.375]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["prediction_list = []\n","prediction_list.append(\"---\")\n","\n","frame_counter = 0\n","for tensor, label in train_data_loader:\n","    i = 0\n","    while True:\n","        tensor16 = tensor[i:i+window_size]\n","        print(tensor16.shape)\n","#         input_tensor = np.stack(tensor16[: window_size], axis=1)\n","        print(input_tensor.shape)\n","        input_tensor = input_tensor.astype(np.float32)\n","        input_tensor = torch.from_numpy(input_tensor)\n","        with torch.no_grad():\n","            print(input_tensor.shape)\n","            outputs = model(input_tensor)[0]\n","        gloss = str(classes[outputs.argmax().item()])\n","        if outputs.max() > threshold:\n","            if gloss != prediction_list[-1] and len(prediction_list):\n","                if gloss != \"---\":\n","                    prediction_list.append(gloss)\n","            tensor16.clear()\n","            i += window_size\n","\n","    text = \"  \".join(prediction_list)\n","    text_div = np.zeros((50, frame.shape[1], 3), dtype=np.uint8)\n","    cv2.putText(text_div, text, (10, 30), cv2.FONT_HERSHEY_COMPLEX, 0.7, (255, 255, 255), 2)\n","\n","    frame = np.concatenate((frame, text_div), axis=0)\n","    writer.write(frame)\n","writer.release()\n","cap.release()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
